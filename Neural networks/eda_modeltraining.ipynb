{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Alphabets_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>C</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>T</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  \\\n",
       "0          T     2     8      3       5      1     8    13      0      6   \n",
       "1          I     5    12      3       7      2    10     5      5      4   \n",
       "2          D     4    11      6       8      6    10     6      2      6   \n",
       "3          N     7    11      6       6      3     5     9      4      6   \n",
       "4          G     2     1      3       1      1     8     6      6      6   \n",
       "...      ...   ...   ...    ...     ...    ...   ...   ...    ...    ...   \n",
       "19995      D     2     2      3       3      2     7     7      7      6   \n",
       "19996      C     7    10      8       8      4     4     8      6      9   \n",
       "19997      T     6     9      6       7      5     6    11      3      7   \n",
       "19998      S     2     3      4       2      1     8     7      2      6   \n",
       "19999      A     4     9      6       6      2     9     5      3      1   \n",
       "\n",
       "       xybar  x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
       "0          6      10       8      0       8      0       8  \n",
       "1         13       3       9      2       8      4      10  \n",
       "2         10       3       7      3       7      3       9  \n",
       "3          4       4      10      6      10      2       8  \n",
       "4          6       5       9      1       7      5      10  \n",
       "...      ...     ...     ...    ...     ...    ...     ...  \n",
       "19995      6       6       4      2       8      3       7  \n",
       "19996     12       9      13      2       9      3       7  \n",
       "19997     11       9       5      2      12      2       4  \n",
       "19998     10       6       8      1       9      5       8  \n",
       "19999      8       1       8      2       7      2       8  \n",
       "\n",
       "[20000 rows x 17 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   letter  20000 non-null  object\n",
      " 1   xbox    20000 non-null  int64 \n",
      " 2   ybox    20000 non-null  int64 \n",
      " 3   width   20000 non-null  int64 \n",
      " 4   height  20000 non-null  int64 \n",
      " 5   onpix   20000 non-null  int64 \n",
      " 6   xbar    20000 non-null  int64 \n",
      " 7   ybar    20000 non-null  int64 \n",
      " 8   x2bar   20000 non-null  int64 \n",
      " 9   y2bar   20000 non-null  int64 \n",
      " 10  xybar   20000 non-null  int64 \n",
      " 11  x2ybar  20000 non-null  int64 \n",
      " 12  xy2bar  20000 non-null  int64 \n",
      " 13  xedge   20000 non-null  int64 \n",
      " 14  xedgey  20000 non-null  int64 \n",
      " 15  yedge   20000 non-null  int64 \n",
      " 16  yedgex  20000 non-null  int64 \n",
      "dtypes: int64(16), object(1)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "letter    0\n",
       "xbox      0\n",
       "ybox      0\n",
       "width     0\n",
       "height    0\n",
       "onpix     0\n",
       "xbar      0\n",
       "ybar      0\n",
       "x2bar     0\n",
       "y2bar     0\n",
       "xybar     0\n",
       "x2ybar    0\n",
       "xy2bar    0\n",
       "xedge     0\n",
       "xedgey    0\n",
       "yedge     0\n",
       "yedgex    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "data['letter'] = le.fit_transform(data['letter'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independent and Dependent split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('letter', axis= 1)\n",
    "y = data['letter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  xybar  \\\n",
       "0         2     8      3       5      1     8    13      0      6      6   \n",
       "1         5    12      3       7      2    10     5      5      4     13   \n",
       "2         4    11      6       8      6    10     6      2      6     10   \n",
       "3         7    11      6       6      3     5     9      4      6      4   \n",
       "4         2     1      3       1      1     8     6      6      6      6   \n",
       "...     ...   ...    ...     ...    ...   ...   ...    ...    ...    ...   \n",
       "19995     2     2      3       3      2     7     7      7      6      6   \n",
       "19996     7    10      8       8      4     4     8      6      9     12   \n",
       "19997     6     9      6       7      5     6    11      3      7     11   \n",
       "19998     2     3      4       2      1     8     7      2      6     10   \n",
       "19999     4     9      6       6      2     9     5      3      1      8   \n",
       "\n",
       "       x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
       "0          10       8      0       8      0       8  \n",
       "1           3       9      2       8      4      10  \n",
       "2           3       7      3       7      3       9  \n",
       "3           4      10      6      10      2       8  \n",
       "4           5       9      1       7      5      10  \n",
       "...       ...     ...    ...     ...    ...     ...  \n",
       "19995       6       4      2       8      3       7  \n",
       "19996       9      13      2       9      3       7  \n",
       "19997       9       5      2      12      2       4  \n",
       "19998       6       8      1       9      5       8  \n",
       "19999       1       8      2       7      2       8  \n",
       "\n",
       "[20000 rows x 16 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        19\n",
       "1         8\n",
       "2         3\n",
       "3        13\n",
       "4         6\n",
       "         ..\n",
       "19995     3\n",
       "19996     2\n",
       "19997    19\n",
       "19998    18\n",
       "19999     0\n",
       "Name: letter, Length: 20000, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_encoded = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5894</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8958</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7671</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11964</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  xybar  \\\n",
       "5894      4     7      5       5      4     6     7      3      7     11   \n",
       "3728      4     7      6       5      5     6     8      3      7     11   \n",
       "8958      3     5      4       3      3     7     8      5      5      7   \n",
       "7671      4    10      6       7      6     5     7      5      7      6   \n",
       "5999      4    10      6       8      4     8    11      2      3      4   \n",
       "...     ...   ...    ...     ...    ...   ...   ...    ...    ...    ...   \n",
       "11284     5    11      4       6      3     7     7      4      3      9   \n",
       "11964     3     7      5       5      4     9    11      6      4      6   \n",
       "5390      3     4      6       3      2     9     6      2      8     10   \n",
       "860       3     8      4       6      2     7     8      0      8     14   \n",
       "15795     1     3      2       2      1    10     7      1      5     11   \n",
       "\n",
       "       x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
       "5894        8       9      3       8      4       8  \n",
       "3728        8       9      3       8      4       7  \n",
       "8958        7       6      5       9      2       6  \n",
       "7671        6      12      3       8      6       9  \n",
       "5999       10       9      3      11      1       8  \n",
       "...       ...     ...    ...     ...    ...     ...  \n",
       "11284       6       7      3      10      8       7  \n",
       "11964       5       7      2       8      6       4  \n",
       "5390        3       7      2       7      3       9  \n",
       "860         6       6      0       8      1       7  \n",
       "15795       4       8      0       7      0       7  \n",
       "\n",
       "[16000 rows x 16 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10650</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8668</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13902</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4073</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7442</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15196</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  xybar  \\\n",
       "10650     3     6      5       6      4     6     7      3      8      8   \n",
       "2041      4    11      6       8      8     7     8      3      5      6   \n",
       "8668      3     4      5       3      2    10     2      2      1      9   \n",
       "1114      2     4      2       3      2     7     7      5      7      7   \n",
       "13902     4     5      5       7      3     8     7      8      6      6   \n",
       "...     ...   ...    ...     ...    ...   ...   ...    ...    ...    ...   \n",
       "4073      4     7      6       5      7     6     6      3      2      8   \n",
       "7442      2     1      3       3      1     6    12      3      6      8   \n",
       "9999      5    10      7       9      4     8     5      9      8      5   \n",
       "1870      4     5      5       7      5    10    11      5      4      5   \n",
       "15196     2     5      4       4      2     7    10      1      6      7   \n",
       "\n",
       "       x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
       "10650       6       9      3       7      7       6  \n",
       "2041        6      10      6      11      7       5  \n",
       "8668        2       9      2       6      2       8  \n",
       "1114        6       8      2       8      5      10  \n",
       "13902       7       9      3       8      5       9  \n",
       "...       ...     ...    ...     ...    ...     ...  \n",
       "4073        6       7      3       7     11       2  \n",
       "7442       11       7      1      11      1       7  \n",
       "9999        4       8      3       8      4       8  \n",
       "1870        8       8      5      10      9       5  \n",
       "15196      11       8      1      11      2       8  \n",
       "\n",
       "[4000 rows x 16 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Scales the training and testing data separately using StandardScaler.\n",
    "\n",
    "    Args:\n",
    "    X_train (np.array): The training features.\n",
    "    X_test (np.array): The testing features.\n",
    "\n",
    "    Returns:\n",
    "    np.array: Scaled training features.\n",
    "    np.array: Scaled testing features.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)  \n",
    "    X_test_scaled = scaler.transform(X_test)        \n",
    "    \n",
    "    return X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_test_scaled = scale_data(X_train= X_train, X_test= X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.53599158, -0.31546285, -0.06013429, ..., -0.86473548,\n",
       "         1.28957403, -1.11481354],\n",
       "       [-0.01291349,  1.19809287,  0.43581861, ...,  1.72720301,\n",
       "         1.28957403, -1.73329539],\n",
       "       [-0.53599158, -0.92088514, -0.06013429, ..., -1.5127201 ,\n",
       "        -0.65897489,  0.12215017],\n",
       "       ...,\n",
       "       [ 0.5101646 ,  0.89538173,  0.9317715 , ..., -0.21675086,\n",
       "         0.12044468,  0.12215017],\n",
       "       [-0.01291349, -0.618174  , -0.06013429, ...,  1.07921839,\n",
       "         2.06899359, -1.73329539],\n",
       "       [-1.05906966, -0.618174  , -0.55608718, ...,  1.72720301,\n",
       "        -0.65897489,  0.12215017]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01291349, -0.01275171, -0.06013429, ..., -0.21675086,\n",
       "         0.12044468,  0.12215017],\n",
       "       [-0.01291349, -0.01275171,  0.43581861, ..., -0.21675086,\n",
       "         0.12044468, -0.49633169],\n",
       "       [-0.53599158, -0.618174  , -0.55608718, ...,  0.43123377,\n",
       "        -0.65897489, -1.11481354],\n",
       "       ...,\n",
       "       [-0.53599158, -0.92088514,  0.43581861, ..., -0.86473548,\n",
       "        -0.2692651 ,  0.74063202],\n",
       "       [-0.53599158,  0.28995944, -0.55608718, ..., -0.21675086,\n",
       "        -1.04868467, -0.49633169],\n",
       "       [-1.58214775, -1.22359629, -1.54799298, ..., -0.86473548,\n",
       "        -1.43839445, -0.49633169]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(data= X_train_scaled,columns=X.columns)\n",
    "X_test = pd.DataFrame(data= X_test_scaled, columns= X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.012913</td>\n",
       "      <td>-0.012752</td>\n",
       "      <td>-0.060134</td>\n",
       "      <td>-0.166388</td>\n",
       "      <td>0.225460</td>\n",
       "      <td>-0.442033</td>\n",
       "      <td>-0.212561</td>\n",
       "      <td>-0.603148</td>\n",
       "      <td>0.761007</td>\n",
       "      <td>1.088793</td>\n",
       "      <td>0.590471</td>\n",
       "      <td>0.513941</td>\n",
       "      <td>-0.019484</td>\n",
       "      <td>-0.216751</td>\n",
       "      <td>0.120445</td>\n",
       "      <td>0.122150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.012913</td>\n",
       "      <td>-0.012752</td>\n",
       "      <td>0.435819</td>\n",
       "      <td>-0.166388</td>\n",
       "      <td>0.682088</td>\n",
       "      <td>-0.442033</td>\n",
       "      <td>0.217398</td>\n",
       "      <td>-0.603148</td>\n",
       "      <td>0.761007</td>\n",
       "      <td>1.088793</td>\n",
       "      <td>0.590471</td>\n",
       "      <td>0.513941</td>\n",
       "      <td>-0.019484</td>\n",
       "      <td>-0.216751</td>\n",
       "      <td>0.120445</td>\n",
       "      <td>-0.496332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.535992</td>\n",
       "      <td>-0.618174</td>\n",
       "      <td>-0.556087</td>\n",
       "      <td>-1.048935</td>\n",
       "      <td>-0.231168</td>\n",
       "      <td>0.050414</td>\n",
       "      <td>0.217398</td>\n",
       "      <td>0.134619</td>\n",
       "      <td>-0.075322</td>\n",
       "      <td>-0.516763</td>\n",
       "      <td>0.209675</td>\n",
       "      <td>-0.926257</td>\n",
       "      <td>0.838118</td>\n",
       "      <td>0.431234</td>\n",
       "      <td>-0.658975</td>\n",
       "      <td>-1.114814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.012913</td>\n",
       "      <td>0.895382</td>\n",
       "      <td>0.435819</td>\n",
       "      <td>0.716160</td>\n",
       "      <td>1.138715</td>\n",
       "      <td>-0.934480</td>\n",
       "      <td>-0.212561</td>\n",
       "      <td>0.134619</td>\n",
       "      <td>0.761007</td>\n",
       "      <td>-0.918152</td>\n",
       "      <td>-0.171120</td>\n",
       "      <td>1.954139</td>\n",
       "      <td>-0.019484</td>\n",
       "      <td>-0.216751</td>\n",
       "      <td>0.899864</td>\n",
       "      <td>0.740632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.012913</td>\n",
       "      <td>0.895382</td>\n",
       "      <td>0.435819</td>\n",
       "      <td>1.157434</td>\n",
       "      <td>0.225460</td>\n",
       "      <td>0.542861</td>\n",
       "      <td>1.507277</td>\n",
       "      <td>-0.972031</td>\n",
       "      <td>-0.911651</td>\n",
       "      <td>-1.720930</td>\n",
       "      <td>1.352061</td>\n",
       "      <td>0.513941</td>\n",
       "      <td>-0.019484</td>\n",
       "      <td>1.727203</td>\n",
       "      <td>-1.048685</td>\n",
       "      <td>0.122150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>0.510165</td>\n",
       "      <td>1.198093</td>\n",
       "      <td>-0.556087</td>\n",
       "      <td>0.274886</td>\n",
       "      <td>-0.231168</td>\n",
       "      <td>0.050414</td>\n",
       "      <td>-0.212561</td>\n",
       "      <td>-0.234264</td>\n",
       "      <td>-0.911651</td>\n",
       "      <td>0.286015</td>\n",
       "      <td>-0.171120</td>\n",
       "      <td>-0.446191</td>\n",
       "      <td>-0.019484</td>\n",
       "      <td>1.079218</td>\n",
       "      <td>1.679284</td>\n",
       "      <td>-0.496332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>-0.535992</td>\n",
       "      <td>-0.012752</td>\n",
       "      <td>-0.060134</td>\n",
       "      <td>-0.166388</td>\n",
       "      <td>0.225460</td>\n",
       "      <td>1.035308</td>\n",
       "      <td>1.507277</td>\n",
       "      <td>0.503503</td>\n",
       "      <td>-0.493487</td>\n",
       "      <td>-0.918152</td>\n",
       "      <td>-0.551915</td>\n",
       "      <td>-0.446191</td>\n",
       "      <td>-0.448284</td>\n",
       "      <td>-0.216751</td>\n",
       "      <td>0.899864</td>\n",
       "      <td>-2.351777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>-0.535992</td>\n",
       "      <td>-0.920885</td>\n",
       "      <td>0.435819</td>\n",
       "      <td>-1.048935</td>\n",
       "      <td>-0.687795</td>\n",
       "      <td>1.035308</td>\n",
       "      <td>-0.642521</td>\n",
       "      <td>-0.972031</td>\n",
       "      <td>1.179172</td>\n",
       "      <td>0.687404</td>\n",
       "      <td>-1.313506</td>\n",
       "      <td>-0.446191</td>\n",
       "      <td>-0.448284</td>\n",
       "      <td>-0.864735</td>\n",
       "      <td>-0.269265</td>\n",
       "      <td>0.740632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>-0.535992</td>\n",
       "      <td>0.289959</td>\n",
       "      <td>-0.556087</td>\n",
       "      <td>0.274886</td>\n",
       "      <td>-0.687795</td>\n",
       "      <td>0.050414</td>\n",
       "      <td>0.217398</td>\n",
       "      <td>-1.709798</td>\n",
       "      <td>1.179172</td>\n",
       "      <td>2.292960</td>\n",
       "      <td>-0.171120</td>\n",
       "      <td>-0.926257</td>\n",
       "      <td>-1.305886</td>\n",
       "      <td>-0.216751</td>\n",
       "      <td>-1.048685</td>\n",
       "      <td>-0.496332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>-1.582148</td>\n",
       "      <td>-1.223596</td>\n",
       "      <td>-1.547993</td>\n",
       "      <td>-1.490209</td>\n",
       "      <td>-1.144423</td>\n",
       "      <td>1.527755</td>\n",
       "      <td>-0.212561</td>\n",
       "      <td>-1.340915</td>\n",
       "      <td>-0.075322</td>\n",
       "      <td>1.088793</td>\n",
       "      <td>-0.932710</td>\n",
       "      <td>0.033875</td>\n",
       "      <td>-1.305886</td>\n",
       "      <td>-0.864735</td>\n",
       "      <td>-1.438394</td>\n",
       "      <td>-0.496332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           xbox      ybox     width    height     onpix      xbar      ybar  \\\n",
       "0     -0.012913 -0.012752 -0.060134 -0.166388  0.225460 -0.442033 -0.212561   \n",
       "1     -0.012913 -0.012752  0.435819 -0.166388  0.682088 -0.442033  0.217398   \n",
       "2     -0.535992 -0.618174 -0.556087 -1.048935 -0.231168  0.050414  0.217398   \n",
       "3     -0.012913  0.895382  0.435819  0.716160  1.138715 -0.934480 -0.212561   \n",
       "4     -0.012913  0.895382  0.435819  1.157434  0.225460  0.542861  1.507277   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "15995  0.510165  1.198093 -0.556087  0.274886 -0.231168  0.050414 -0.212561   \n",
       "15996 -0.535992 -0.012752 -0.060134 -0.166388  0.225460  1.035308  1.507277   \n",
       "15997 -0.535992 -0.920885  0.435819 -1.048935 -0.687795  1.035308 -0.642521   \n",
       "15998 -0.535992  0.289959 -0.556087  0.274886 -0.687795  0.050414  0.217398   \n",
       "15999 -1.582148 -1.223596 -1.547993 -1.490209 -1.144423  1.527755 -0.212561   \n",
       "\n",
       "          x2bar     y2bar     xybar    x2ybar    xy2bar     xedge    xedgey  \\\n",
       "0     -0.603148  0.761007  1.088793  0.590471  0.513941 -0.019484 -0.216751   \n",
       "1     -0.603148  0.761007  1.088793  0.590471  0.513941 -0.019484 -0.216751   \n",
       "2      0.134619 -0.075322 -0.516763  0.209675 -0.926257  0.838118  0.431234   \n",
       "3      0.134619  0.761007 -0.918152 -0.171120  1.954139 -0.019484 -0.216751   \n",
       "4     -0.972031 -0.911651 -1.720930  1.352061  0.513941 -0.019484  1.727203   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "15995 -0.234264 -0.911651  0.286015 -0.171120 -0.446191 -0.019484  1.079218   \n",
       "15996  0.503503 -0.493487 -0.918152 -0.551915 -0.446191 -0.448284 -0.216751   \n",
       "15997 -0.972031  1.179172  0.687404 -1.313506 -0.446191 -0.448284 -0.864735   \n",
       "15998 -1.709798  1.179172  2.292960 -0.171120 -0.926257 -1.305886 -0.216751   \n",
       "15999 -1.340915 -0.075322  1.088793 -0.932710  0.033875 -1.305886 -0.864735   \n",
       "\n",
       "          yedge    yedgex  \n",
       "0      0.120445  0.122150  \n",
       "1      0.120445 -0.496332  \n",
       "2     -0.658975 -1.114814  \n",
       "3      0.899864  0.740632  \n",
       "4     -1.048685  0.122150  \n",
       "...         ...       ...  \n",
       "15995  1.679284 -0.496332  \n",
       "15996  0.899864 -2.351777  \n",
       "15997 -0.269265  0.740632  \n",
       "15998 -1.048685 -0.496332  \n",
       "15999 -1.438394 -0.496332  \n",
       "\n",
       "[16000 rows x 16 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.535992</td>\n",
       "      <td>-0.315463</td>\n",
       "      <td>-0.060134</td>\n",
       "      <td>0.274886</td>\n",
       "      <td>0.225460</td>\n",
       "      <td>-0.442033</td>\n",
       "      <td>-0.212561</td>\n",
       "      <td>-0.603148</td>\n",
       "      <td>1.179172</td>\n",
       "      <td>-0.115374</td>\n",
       "      <td>-0.171120</td>\n",
       "      <td>0.513941</td>\n",
       "      <td>-0.019484</td>\n",
       "      <td>-0.864735</td>\n",
       "      <td>1.289574</td>\n",
       "      <td>-1.114814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.012913</td>\n",
       "      <td>1.198093</td>\n",
       "      <td>0.435819</td>\n",
       "      <td>1.157434</td>\n",
       "      <td>2.051970</td>\n",
       "      <td>0.050414</td>\n",
       "      <td>0.217398</td>\n",
       "      <td>-0.603148</td>\n",
       "      <td>-0.075322</td>\n",
       "      <td>-0.918152</td>\n",
       "      <td>-0.171120</td>\n",
       "      <td>0.994007</td>\n",
       "      <td>1.266919</td>\n",
       "      <td>1.727203</td>\n",
       "      <td>1.289574</td>\n",
       "      <td>-1.733295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.535992</td>\n",
       "      <td>-0.920885</td>\n",
       "      <td>-0.060134</td>\n",
       "      <td>-1.048935</td>\n",
       "      <td>-0.687795</td>\n",
       "      <td>1.527755</td>\n",
       "      <td>-2.362360</td>\n",
       "      <td>-0.972031</td>\n",
       "      <td>-1.747981</td>\n",
       "      <td>0.286015</td>\n",
       "      <td>-1.694301</td>\n",
       "      <td>0.513941</td>\n",
       "      <td>-0.448284</td>\n",
       "      <td>-1.512720</td>\n",
       "      <td>-0.658975</td>\n",
       "      <td>0.122150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.059070</td>\n",
       "      <td>-0.920885</td>\n",
       "      <td>-1.547993</td>\n",
       "      <td>-1.048935</td>\n",
       "      <td>-0.687795</td>\n",
       "      <td>0.050414</td>\n",
       "      <td>-0.212561</td>\n",
       "      <td>0.134619</td>\n",
       "      <td>0.761007</td>\n",
       "      <td>-0.516763</td>\n",
       "      <td>-0.171120</td>\n",
       "      <td>0.033875</td>\n",
       "      <td>-0.448284</td>\n",
       "      <td>-0.216751</td>\n",
       "      <td>0.510154</td>\n",
       "      <td>1.359114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.012913</td>\n",
       "      <td>-0.618174</td>\n",
       "      <td>-0.060134</td>\n",
       "      <td>0.716160</td>\n",
       "      <td>-0.231168</td>\n",
       "      <td>0.542861</td>\n",
       "      <td>-0.212561</td>\n",
       "      <td>1.241270</td>\n",
       "      <td>0.342843</td>\n",
       "      <td>-0.918152</td>\n",
       "      <td>0.209675</td>\n",
       "      <td>0.513941</td>\n",
       "      <td>-0.019484</td>\n",
       "      <td>-0.216751</td>\n",
       "      <td>0.510154</td>\n",
       "      <td>0.740632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>-0.012913</td>\n",
       "      <td>-0.012752</td>\n",
       "      <td>0.435819</td>\n",
       "      <td>-0.166388</td>\n",
       "      <td>1.595343</td>\n",
       "      <td>-0.442033</td>\n",
       "      <td>-0.642521</td>\n",
       "      <td>-0.603148</td>\n",
       "      <td>-1.329816</td>\n",
       "      <td>-0.115374</td>\n",
       "      <td>-0.171120</td>\n",
       "      <td>-0.446191</td>\n",
       "      <td>-0.019484</td>\n",
       "      <td>-0.864735</td>\n",
       "      <td>2.848413</td>\n",
       "      <td>-3.588741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>-1.059070</td>\n",
       "      <td>-1.829019</td>\n",
       "      <td>-1.052040</td>\n",
       "      <td>-1.048935</td>\n",
       "      <td>-1.144423</td>\n",
       "      <td>-0.442033</td>\n",
       "      <td>1.937237</td>\n",
       "      <td>-0.603148</td>\n",
       "      <td>0.342843</td>\n",
       "      <td>-0.115374</td>\n",
       "      <td>1.732856</td>\n",
       "      <td>-0.446191</td>\n",
       "      <td>-0.877085</td>\n",
       "      <td>1.727203</td>\n",
       "      <td>-1.048685</td>\n",
       "      <td>-0.496332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>0.510165</td>\n",
       "      <td>0.895382</td>\n",
       "      <td>0.931772</td>\n",
       "      <td>1.598707</td>\n",
       "      <td>0.225460</td>\n",
       "      <td>0.542861</td>\n",
       "      <td>-1.072481</td>\n",
       "      <td>1.610154</td>\n",
       "      <td>1.179172</td>\n",
       "      <td>-1.319541</td>\n",
       "      <td>-0.932710</td>\n",
       "      <td>0.033875</td>\n",
       "      <td>-0.019484</td>\n",
       "      <td>-0.216751</td>\n",
       "      <td>0.120445</td>\n",
       "      <td>0.122150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>-0.012913</td>\n",
       "      <td>-0.618174</td>\n",
       "      <td>-0.060134</td>\n",
       "      <td>0.716160</td>\n",
       "      <td>0.682088</td>\n",
       "      <td>1.527755</td>\n",
       "      <td>1.507277</td>\n",
       "      <td>0.134619</td>\n",
       "      <td>-0.493487</td>\n",
       "      <td>-1.319541</td>\n",
       "      <td>0.590471</td>\n",
       "      <td>0.033875</td>\n",
       "      <td>0.838118</td>\n",
       "      <td>1.079218</td>\n",
       "      <td>2.068994</td>\n",
       "      <td>-1.733295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>-1.059070</td>\n",
       "      <td>-0.618174</td>\n",
       "      <td>-0.556087</td>\n",
       "      <td>-0.607662</td>\n",
       "      <td>-0.687795</td>\n",
       "      <td>0.050414</td>\n",
       "      <td>1.077318</td>\n",
       "      <td>-1.340915</td>\n",
       "      <td>0.342843</td>\n",
       "      <td>-0.516763</td>\n",
       "      <td>1.732856</td>\n",
       "      <td>0.033875</td>\n",
       "      <td>-0.877085</td>\n",
       "      <td>1.727203</td>\n",
       "      <td>-0.658975</td>\n",
       "      <td>0.122150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          xbox      ybox     width    height     onpix      xbar      ybar  \\\n",
       "0    -0.535992 -0.315463 -0.060134  0.274886  0.225460 -0.442033 -0.212561   \n",
       "1    -0.012913  1.198093  0.435819  1.157434  2.051970  0.050414  0.217398   \n",
       "2    -0.535992 -0.920885 -0.060134 -1.048935 -0.687795  1.527755 -2.362360   \n",
       "3    -1.059070 -0.920885 -1.547993 -1.048935 -0.687795  0.050414 -0.212561   \n",
       "4    -0.012913 -0.618174 -0.060134  0.716160 -0.231168  0.542861 -0.212561   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3995 -0.012913 -0.012752  0.435819 -0.166388  1.595343 -0.442033 -0.642521   \n",
       "3996 -1.059070 -1.829019 -1.052040 -1.048935 -1.144423 -0.442033  1.937237   \n",
       "3997  0.510165  0.895382  0.931772  1.598707  0.225460  0.542861 -1.072481   \n",
       "3998 -0.012913 -0.618174 -0.060134  0.716160  0.682088  1.527755  1.507277   \n",
       "3999 -1.059070 -0.618174 -0.556087 -0.607662 -0.687795  0.050414  1.077318   \n",
       "\n",
       "         x2bar     y2bar     xybar    x2ybar    xy2bar     xedge    xedgey  \\\n",
       "0    -0.603148  1.179172 -0.115374 -0.171120  0.513941 -0.019484 -0.864735   \n",
       "1    -0.603148 -0.075322 -0.918152 -0.171120  0.994007  1.266919  1.727203   \n",
       "2    -0.972031 -1.747981  0.286015 -1.694301  0.513941 -0.448284 -1.512720   \n",
       "3     0.134619  0.761007 -0.516763 -0.171120  0.033875 -0.448284 -0.216751   \n",
       "4     1.241270  0.342843 -0.918152  0.209675  0.513941 -0.019484 -0.216751   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3995 -0.603148 -1.329816 -0.115374 -0.171120 -0.446191 -0.019484 -0.864735   \n",
       "3996 -0.603148  0.342843 -0.115374  1.732856 -0.446191 -0.877085  1.727203   \n",
       "3997  1.610154  1.179172 -1.319541 -0.932710  0.033875 -0.019484 -0.216751   \n",
       "3998  0.134619 -0.493487 -1.319541  0.590471  0.033875  0.838118  1.079218   \n",
       "3999 -1.340915  0.342843 -0.516763  1.732856  0.033875 -0.877085  1.727203   \n",
       "\n",
       "         yedge    yedgex  \n",
       "0     1.289574 -1.114814  \n",
       "1     1.289574 -1.733295  \n",
       "2    -0.658975  0.122150  \n",
       "3     0.510154  1.359114  \n",
       "4     0.510154  0.740632  \n",
       "...        ...       ...  \n",
       "3995  2.848413 -3.588741  \n",
       "3996 -1.048685 -0.496332  \n",
       "3997  0.120445  0.122150  \n",
       "3998  2.068994 -1.733295  \n",
       "3999 -0.658975  0.122150  \n",
       "\n",
       "[4000 rows x 16 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Iteration 1/15 | Parameters: {'hidden_layers': (64,), 'activation': np.str_('relu'), 'learning_rate': np.float64(0.001), 'dropout_rate': np.float64(0.2), 'batch_size': np.int64(32), 'epochs': np.int64(30)} | Average CV Accuracy: 0.8636\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Iteration 2/15 | Parameters: {'hidden_layers': (64,), 'activation': np.str_('relu'), 'learning_rate': np.float64(0.001), 'dropout_rate': np.float64(0.2), 'batch_size': np.int64(64), 'epochs': np.int64(30)} | Average CV Accuracy: 0.8502\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Iteration 3/15 | Parameters: {'hidden_layers': (64,), 'activation': np.str_('relu'), 'learning_rate': np.float64(0.001), 'dropout_rate': np.float64(0.2), 'batch_size': np.int64(64), 'epochs': np.int64(30)} | Average CV Accuracy: 0.8586\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Iteration 4/15 | Parameters: {'hidden_layers': (64,), 'activation': np.str_('relu'), 'learning_rate': np.float64(0.001), 'dropout_rate': np.float64(0.2), 'batch_size': np.int64(64), 'epochs': np.int64(30)} | Average CV Accuracy: 0.8496\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Iteration 5/15 | Parameters: {'hidden_layers': (128,), 'activation': np.str_('relu'), 'learning_rate': np.float64(0.001), 'dropout_rate': np.float64(0.2), 'batch_size': np.int64(64), 'epochs': np.int64(30)} | Average CV Accuracy: 0.8879\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Iteration 6/15 | Parameters: {'hidden_layers': (64,), 'activation': np.str_('relu'), 'learning_rate': np.float64(0.001), 'dropout_rate': np.float64(0.2), 'batch_size': np.int64(32), 'epochs': np.int64(30)} | Average CV Accuracy: 0.8679\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Iteration 7/15 | Parameters: {'hidden_layers': (128,), 'activation': np.str_('relu'), 'learning_rate': np.float64(0.001), 'dropout_rate': np.float64(0.2), 'batch_size': np.int64(64), 'epochs': np.int64(30)} | Average CV Accuracy: 0.8920\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Iteration 8/15 | Parameters: {'hidden_layers': (128,), 'activation': np.str_('relu'), 'learning_rate': np.float64(0.001), 'dropout_rate': np.float64(0.2), 'batch_size': np.int64(64), 'epochs': np.int64(30)} | Average CV Accuracy: 0.8897\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Iteration 9/15 | Parameters: {'hidden_layers': (64,), 'activation': np.str_('relu'), 'learning_rate': np.float64(0.001), 'dropout_rate': np.float64(0.2), 'batch_size': np.int64(32), 'epochs': np.int64(30)} | Average CV Accuracy: 0.8581\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Iteration 10/15 | Parameters: {'hidden_layers': (64,), 'activation': np.str_('relu'), 'learning_rate': np.float64(0.001), 'dropout_rate': np.float64(0.2), 'batch_size': np.int64(32), 'epochs': np.int64(30)} | Average CV Accuracy: 0.8625\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Iteration 11/15 | Parameters: {'hidden_layers': (64,), 'activation': np.str_('relu'), 'learning_rate': np.float64(0.001), 'dropout_rate': np.float64(0.2), 'batch_size': np.int64(32), 'epochs': np.int64(30)} | Average CV Accuracy: 0.8597\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Iteration 12/15 | Parameters: {'hidden_layers': (128,), 'activation': np.str_('relu'), 'learning_rate': np.float64(0.001), 'dropout_rate': np.float64(0.2), 'batch_size': np.int64(64), 'epochs': np.int64(30)} | Average CV Accuracy: 0.8856\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Iteration 13/15 | Parameters: {'hidden_layers': (64,), 'activation': np.str_('relu'), 'learning_rate': np.float64(0.001), 'dropout_rate': np.float64(0.2), 'batch_size': np.int64(32), 'epochs': np.int64(30)} | Average CV Accuracy: 0.8679\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Iteration 14/15 | Parameters: {'hidden_layers': (64,), 'activation': np.str_('relu'), 'learning_rate': np.float64(0.001), 'dropout_rate': np.float64(0.2), 'batch_size': np.int64(64), 'epochs': np.int64(30)} | Average CV Accuracy: 0.8494\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Iteration 15/15 | Parameters: {'hidden_layers': (64,), 'activation': np.str_('relu'), 'learning_rate': np.float64(0.001), 'dropout_rate': np.float64(0.2), 'batch_size': np.int64(64), 'epochs': np.int64(30)} | Average CV Accuracy: 0.8488\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Function to create a model\n",
    "def create_model(hidden_layers=(64,), activation='relu', learning_rate=0.001, dropout_rate=0.2, input_dim=None, output_dim=None):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_layers[0], activation=activation, input_dim=input_dim))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    for neurons in hidden_layers[1:]:\n",
    "        model.add(Dense(neurons, activation=activation))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(output_dim, activation='softmax'))\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Function to train and evaluate a model\n",
    "def train_evaluate_model(model, X_train, y_train, batch_size=32, epochs=50):\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy', patience=2, restore_best_weights=True, verbose=1)\n",
    "    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=0, validation_split=0.2, callbacks=[early_stopping])\n",
    "    return history\n",
    "\n",
    "# Random search function with early stopping\n",
    "def random_search_tuning(X_train, y_train, n_iter=15, n_folds=3, early_stop_threshold=0.98):\n",
    "    param_distributions = {\n",
    "        'hidden_layers': [(64,), (128,)],\n",
    "        'activation': ['relu'],\n",
    "        'learning_rate': [0.001],\n",
    "        'dropout_rate': [0.2],\n",
    "        'batch_size': [32, 64],\n",
    "        'epochs': [30]  # Start with fewer epochs\n",
    "    }\n",
    "\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "    best_avg_accuracy = 0\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "\n",
    "    # Convert X_train from DataFrame to NumPy array\n",
    "    X_train = X_train.to_numpy()\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        params = {\n",
    "            'hidden_layers': param_distributions['hidden_layers'][np.random.randint(len(param_distributions['hidden_layers']))],\n",
    "            'activation': np.random.choice(param_distributions['activation']),\n",
    "            'learning_rate': np.random.choice(param_distributions['learning_rate']),\n",
    "            'dropout_rate': np.random.choice(param_distributions['dropout_rate']),\n",
    "            'batch_size': np.random.choice(param_distributions['batch_size']),\n",
    "            'epochs': np.random.choice(param_distributions['epochs'])\n",
    "        }\n",
    "        \n",
    "        fold_accuracies = []\n",
    "        for train_idx, val_idx in kf.split(X_train):\n",
    "            X_fold_train, X_fold_val = X_train[train_idx], X_train[val_idx]\n",
    "            y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n",
    "            \n",
    "            model = create_model(\n",
    "                hidden_layers=params['hidden_layers'],\n",
    "                activation=params['activation'],\n",
    "                learning_rate=params['learning_rate'],\n",
    "                dropout_rate=params['dropout_rate'],\n",
    "                input_dim=X_train.shape[1],\n",
    "                output_dim=y_train.shape[1]\n",
    "            )\n",
    "            \n",
    "            history = train_evaluate_model(\n",
    "                model, X_fold_train, y_fold_train,\n",
    "                batch_size=params['batch_size'],\n",
    "                epochs=params['epochs']\n",
    "            )\n",
    "            \n",
    "            val_loss, val_accuracy = model.evaluate(X_fold_val, y_fold_val, verbose=0)\n",
    "            fold_accuracies.append(val_accuracy)\n",
    "        \n",
    "        avg_accuracy = np.mean(fold_accuracies)\n",
    "        print(f\"Iteration {i+1}/{n_iter} | Parameters: {params} | Average CV Accuracy: {avg_accuracy:.4f}\")\n",
    "        \n",
    "        if avg_accuracy > best_avg_accuracy:\n",
    "            best_avg_accuracy = avg_accuracy\n",
    "            best_params = params\n",
    "            best_model = model\n",
    "            \n",
    "        # **Early stopping based on high accuracy**\n",
    "        if best_avg_accuracy >= early_stop_threshold:\n",
    "            print(f\"Early stopping at iteration {i+1} with accuracy {best_avg_accuracy:.4f}\")\n",
    "            break  \n",
    "\n",
    "    return best_model, best_params\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Perform Random Search Tuning\n",
    "    best_model_random, best_params_random = random_search_tuning(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_layers': (128,),\n",
       " 'activation': np.str_('relu'),\n",
       " 'learning_rate': np.float64(0.001),\n",
       " 'dropout_rate': np.float64(0.2),\n",
       " 'batch_size': np.int64(64),\n",
       " 'epochs': np.int64(30)}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Sequential name=sequential_230, built=True>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_base_model_default(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Trains a base model with default hyperparameters (no tuning).\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train, y_train: Training dataset.\n",
    "    - X_test, y_test: Test dataset for evaluation.\n",
    "    \n",
    "    Returns:\n",
    "    - trained_model: The trained Keras model.\n",
    "    - history: Training history object.\n",
    "    \"\"\"\n",
    "    # Define base model hyperparameters (default values)\n",
    "    base_params = {\n",
    "        'hidden_layers': (64,),           # Default: 64 neurons in 1 hidden layer\n",
    "        'activation': 'relu',             # Default: ReLU activation\n",
    "        'learning_rate': 0.001,           # Default: learning rate of 0.001\n",
    "        'dropout_rate': 0.2,              # Default: dropout rate of 0.2\n",
    "        'batch_size': 32,                 # Default: batch size of 32\n",
    "        'epochs': 50                      # Default: 50 epochs\n",
    "    }\n",
    "\n",
    "    # Initialize model using the default parameters\n",
    "    model = create_model(\n",
    "        hidden_layers=base_params['hidden_layers'],\n",
    "        activation=base_params['activation'],\n",
    "        learning_rate=base_params['learning_rate'],\n",
    "        dropout_rate=base_params['dropout_rate'],\n",
    "        input_dim=X_train.shape[1],       # Number of input features\n",
    "        output_dim=y_train.shape[1]       # Number of output classes\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    history = train_evaluate_model(\n",
    "        model, X_train, y_train,\n",
    "        batch_size=base_params['batch_size'],\n",
    "        epochs=base_params['epochs']\n",
    "    )\n",
    "\n",
    "    # Evaluate model on test data\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8827 - loss: 0.3983\n",
      "Test Accuracy: 0.8857\n"
     ]
    }
   ],
   "source": [
    "base_model, base_history = train_base_model_default(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluates the model using accuracy, precision, recall, and F1-score.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained model to evaluate.\n",
    "    - X_test: Test dataset features.\n",
    "    - y_test: True labels of the test dataset.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary containing accuracy, precision, recall, and F1-score.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = y_pred.argmax(axis=1)  # Convert probabilities to class labels\n",
    "    y_true_classes = y_test.argmax(axis=1)  # Convert one-hot encoded labels to class labels\n",
    "\n",
    "    metrics = {\n",
    "        \"Accuracy\": accuracy_score(y_true_classes, y_pred_classes),\n",
    "        \"Precision\": precision_score(y_true_classes, y_pred_classes, average=\"weighted\"),\n",
    "        \"Recall\": recall_score(y_true_classes, y_pred_classes, average=\"weighted\"),\n",
    "        \"F1-Score\": f1_score(y_true_classes, y_pred_classes, average=\"weighted\"),\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "{'Accuracy': 0.90025, 'Precision': 0.9020621448762338, 'Recall': 0.90025, 'F1-Score': 0.9002031904802128}\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_model(best_model_random, X_test, y_test)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step\n",
      "{'Accuracy': 0.88575, 'Precision': 0.8898934480417653, 'Recall': 0.88575, 'F1-Score': 0.8863986441927629}\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_model(base_model, X_test, y_test)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
