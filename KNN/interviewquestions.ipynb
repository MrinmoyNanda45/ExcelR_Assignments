{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What are the key hyperparameters in KNN?\n",
    "\n",
    "The key hyperparameters in the K-Nearest Neighbors (KNN) algorithm are:\n",
    "\n",
    "- **n_neighbors**: \n",
    "  - Defines the number of nearest neighbors to consider when making a prediction. A smaller value makes the model sensitive to noise, whereas a larger value may smooth out the decision boundaries.\n",
    "\n",
    "- **weights**: \n",
    "  - Specifies the weight function used in prediction. It can take the following values:\n",
    "    - `'uniform'`: All points in each neighborhood are weighted equally.\n",
    "    - `'distance'`: Closer neighbors have a greater influence on the prediction.\n",
    "\n",
    "- **metric**: \n",
    "  - Specifies the distance metric used to calculate the distance between points. It can be any of the distance metrics supported by the algorithm (e.g., Euclidean, Manhattan).\n",
    "\n",
    "- **algorithm**: \n",
    "  - Specifies the algorithm used to compute the nearest neighbors. Common options include:\n",
    "    - `'auto'`: Automatically selects the best algorithm based on the dataset.\n",
    "    - `'ball_tree'`: A tree structure for efficient neighbor search.\n",
    "    - `'kd_tree'`: A more efficient tree structure than the brute-force method for high-dimensional data.\n",
    "    - `'brute'`: A brute-force method for calculating distances.\n",
    "\n",
    "- **leaf_size**: \n",
    "  - Relevant when using the `ball_tree` or `kd_tree` algorithms. It controls the size of leaf nodes in the tree, impacting the speed of the query and the memory used by the model.\n",
    "\n",
    "- **p**: \n",
    "  - Defines the power parameter for the Minkowski distance metric. When `p = 1`, it uses Manhattan distance, and when `p = 2`, it uses Euclidean distance.\n",
    "\n",
    "- **metric_params**: \n",
    "  - Allows for passing additional arguments to the distance metric. It is usually not commonly used unless you are using custom distance metrics.\n",
    "\n",
    "---\n",
    "## 2. What distance metrics can be used in KNN?\n",
    "\n",
    "In KNN, the distance metric defines how the \"closeness\" of points is measured. The most commonly used distance metrics are:\n",
    "\n",
    "- **Euclidean Distance (p=2)**: \n",
    "  - The straight-line distance between two points in the space, calculated as:\n",
    "\n",
    "  $$d(x, y) = \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2}$$\n",
    "\n",
    "  - This is the default distance metric in KNN.\n",
    "\n",
    "- **Manhattan Distance (p=1)**: \n",
    "  - The sum of the absolute differences between the coordinates of two points, calculated as:\n",
    "\n",
    "  $$d(x, y) = \\sum_{i=1}^{n} |x_i - y_i|$$\n",
    "\n",
    "  - This is useful for grid-like pathfinding problems.\n",
    "\n",
    "- **Minkowski Distance**: \n",
    "  - A generalization of both Euclidean and Manhattan distances, calculated as:\n",
    "\n",
    "  $$d(x, y) = \\left( \\sum_{i=1}^{n} |x_i - y_i|^p \\right)^{1/p}$$\n",
    "\n",
    "  - By varying the value of `p`, it can represent both the Manhattan and Euclidean distances.\n",
    "\n",
    "- **Cosine Similarity**: \n",
    "  - Measures the cosine of the angle between two vectors. It is used when dealing with text data (document similarity), where the magnitude of the vectors doesn't matter, only the direction.\n",
    "\n",
    "- **Hamming Distance**: \n",
    "  - Used for categorical features, this measures the number of positions at which the corresponding elements are different between two strings.\n",
    "\n",
    "- **Chebyshev Distance**: \n",
    "  - This distance metric is defined as the maximum of the absolute differences between the coordinates of two points:\n",
    "\n",
    "  $$d(x, y) = \\max_{i} |x_i - y_i|$$\n",
    "\n",
    "  - It is useful when the dimensions of the data vary greatly.\n",
    "\n",
    "- **Mahalanobis Distance**: \n",
    "  - This distance takes into account the correlations of the data and is useful when the data features are correlated. It is calculated as:\n",
    "\n",
    "  $$d(x, y) = \\sqrt{(x - y)^T S^{-1} (x - y)}$$\n",
    "\n",
    "  - Where \\( S \\) is the covariance matrix of the dataset.\n",
    "\n",
    "These are the most common distance metrics, but KNN can also be customized to use other distance metrics depending on the specific problem.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
